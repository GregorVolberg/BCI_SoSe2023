sd   = 20
nruns = 1000
tstat = numeric(nruns)/0
for (iter in 1 : nruns){
pop1  = rnorm(n1, m1, sd)
pop2  = rnorm(n1, m1, sd)
se    = sd * sqrt((1/n1)+(1/n1))
tstat[iter] = (mean(pop1) - mean(pop2)) / se
}
hist(tstat, xlim= c(-5, 15), ylim = c(0, 0.5),
main = '', xlab = 't', freq=FALSE)
k = curve(dt(x, N-2), -6,6, add=T, type='n')
points(k$x, k$y, type = 'l', col='blue', lwd=2)
points(k$x, k$y, type = 'l', col='blue', lwd=2)
n1   = 50
n2   = 50
N    = n1 + n2
m1   = 177 # mann
m2   = 164 # frau
sd   = 20
nruns = 1000
tstat = numeric(nruns)/0
for (iter in 1 : nruns){
pop1  = rnorm(n1, m1, sd)
pop2  = rnorm(n1, m1, sd)
se    = sd * sqrt((1/n1)+(1/n2))
tstat[iter] = (mean(pop1) - mean(pop2)) / se
}
hist(tstat, xlim= c(-5, 15), ylim = c(0, 0.5),
main = '', xlab = 't', freq=FALSE)
k = curve(dt(x, N-2), -6,6, add=T, type='n')
points(k$x, k$y, type = 'l', col='blue', lwd=2)
pop1  = rnorm(n1, m1, sd);
pop2  = rnorm(n2, m2, sd)
act_t = (mean(pop1) - mean(pop2)) / se  # 2.033195 in Abb.
points(act_t, dt(act_t, N-2), cex=1, lwd = 2, col='red')
act_t
sum(tstat > act_t)
sum(tstat > act_t)/nruns
alpha = 0.05
tcrit = quantile(tstat, 1-alpha)
abline(v = tcrit, col = 'red')
qt(0.95,48)
qt(0.95,98)
cohensd = 0.6
m1 = m2 + cohensd*sd
tstat2 = numeric(nruns)/0
# zweite Verteilung
for (iter in 1 : nruns){
pop1  = rnorm(n1, m1, sd);
pop2  = rnorm(n2, m2, sd)
se    = sd * sqrt((1/n1)+(1/n2))
tstat2[iter] = (mean(pop1) - mean(pop2)) / se
}
hist(tstat2,  freq=FALSE, add=T, col = 'white')
ncp = cohensd * sqrt((n1*n2) / (n1+n2)) # non-centrality parameter. see Faul et al., 2007
k2 = curve(dt(x, N-2, ncp=ncp), 0,15, add=T, type='n')
points(k2$x, k2$y, type = 'l', col='black', lwd=2)
abline(v = tcrit, col = 'red')
sum(tstat2>tcrit)/1000
400+5*200+3*400
400+5*200+3*400+500
?stripchart()
87/318
22/878
(87*856)/(22*231)
400+200+100+10*2000+5*200+200
400+200+100+10*200+5*200+200
5+6+6+5+9+8+13+8+6+8+8+8+8+8+8+6+6+10+12+6
12
getwd()
im = rand(3,3)
im = random(3,3)
im = rnorm(3,3)
im = rnorm(30,30)
image(im)
im
im = matrix(rnorm(30*30), 30, 30)
im
image(im)
400 + 1000+3*600+300
7000.42
700*0.42
24*30
12*14
12*14.
5*15
12*15
720-150
300 - (15*5)
12*30
6*15
34*30
4*15
1020/35
26*30
8+32+18+30
28+32+18+30
28+32+20+30
28+34+20+30
200+6*150+400+300+200+8*50
sqrt(5)
sqrt((4-9)^2 + (9-2)^2)
sqrt((2-9)^2 + (8-2)^2)
0.47-0.25
0.47-1.42
0.25-1.42
r1 = c(2.2,8.6,9.2)
r2 = c(0.22,0.95,1.77)
corr(r1,r2)
cor(r1,r2)
cor.test(r1,r2)
1:40*1/2.9
plot(1:40*1/2.9)
round(plot(1:80*1/2.9))
round(1:80*1/2.9))
round(1:80*1/2.9)
round(40*1/seq(1,2.9,0.1)
)
round(40*(1/seq(1,2.9,0.1)^2)
)
plot(round(40*(1/seq(1,2.9,0.1)^2)))
plot(round(40*(1/seq(1,2.9,0.1))))
16.85 + 112.37
400+200+100+200+300+400+300+200+100+300
400+200+100+200+300+400+300+200+100+300 + 400
qnorm(0.3)
qnorm(0.7)
qnorm(0.8)
qnorm(0.2)
3*25*4
472+24+78+75+75+75+75
12*59
10*59
590+24+78+4*50
2*2*9*15
3780/540
1500 * 80
1500 * 80/3
250 * 80
16500/66
sample(6)
sample(9)
sample(3)
sample(3)
sample(11)
sample(4)
sample(6)
sample(3)
sample(6)
sample(9)
sample(8)
1920 / 1080
1080 / 1920
600*0.5625
28*6
a1=70
a2 = 38
b1=88
b2= 72
c1 = a1 / (a1+a2)
c1
a1=70
a2 = 38
b1=88
b2= 72
p1 = a1 / (a1+a2)
c1 = p1/(1-p1)
p2 = b1 / (b1+b2)
c1 = p1/(1-p1)
c2 = p2/(1-p2)
c1
c1(c2)
c1/c2
c2/c1
1/(c2/c1)
c1b = p1b/(1-p1b)
c2b = p2b/(1-p2b)
p1b = a2 / (a2+a1)
p2b = b2 / (b2+b1)
c1b = p1b/(1-p1b)
c2b = p2b/(1-p2b)
p1
p2
p1b
c1b
c1b/c2b
1/c1b/c2b
c1b/c2b
c1/c2
1/(c1/c2)
p1
p2
c1
c2
p1b
c1b
1c1
1/c1
28*7
28*6
getwd()
library(psych)
library(foreign)
dat=read.spss('backhaus_beispiel.sav', to.data.frame=T)
install.packages("psych")
library(foreign)
library(psych)
dat=read.spss('backhaus_beispiel.sav', to.data.frame=T)
dat
R = cor(dat)
R
eye(3)
diag(5)
dat
ncol(dat)
I = diag(ncol(dat))
as.data.frame(I)
I = as.data.frame(diag(ncol(dat)))
I
chisq.test(lower.tri(I), lower.tri(R))
chisq.test(I, R)
# Daten (aus Backhaus et al., 2003, Kap. 5)
####
x1 <- c(1,2,4,5,2,3)
x2 <- c(1,6,5,6,3,4)
x3 <- c(2,3,4,6,3,4)
x4 <- c(1,3,4,2,5,6)
x5 <- c(2,4,5,3,7,7)
streichfette = data.frame(x1, x2, x3, x4, x5)
streichfette
N <- nrow(streichfette) # Anzahl Reihen (Beobachtungen)
N <- nrow(streichfette) # Anzahl Reihen (Beobachtungen)
K <- ncol(streichfette) # Anzahl Spalten (Variablen)
R <- cor(streichfette)  # Korrelationsmatrix R fÃ¼r Streichfette
Pruefgroesse = -log(det(R))* (N-1-(2*K+5)/6) # siehe Folie 9
df <- K*(K-1)/2  # Freiheitsgrade
Pruefgroesse
p = matrix(numeric(K*N)/0, N) # Matrix mit Residuen, N rows by K columns
for (i in 1:K){
p[,i] = resid(lm(streichfette[,i]~., data=streichfette[,-i]))}
Q = cor(p)     # Matrix mit Partialkorrelationen, K*K
sum1 = sum(R^2)-K # subtrahiere Summe der Quadrate der diagonalen Elemente
sum2 = sum(Q^2)-K # subtrahiere Summe der Quadrate der diagonalen Elemente
KMO = sum1/(sum1+sum2) # KMO-Wert
KMO
KMO(R)
cortest.bartlett(dat, n = 5)
solution1 = principal(R, nfactors=5, rotate='none')
plot(solution1$values, type='b', ylab='Eigenwerte', xlab='Faktoren')
print(solution1$loadings, cut=0,digits=7, sort=T)
solution2 = principal(R, nfactors=2, rotate='varimax', scores=T)
print(solution2$loadings, cut=0,digits=7, sort=T)
factors = eigen(R)
factors
Z = scale(streichfette)
eigvalues = eigen(R)$values
plot(eigvalues, type='b') # nur 1 und 2 nach Scree Test
eig = eigvalues[1:2]
eigvector = eigen(R)$vectors[,1:2]
ladung = eigvector%*%diag(sqrt(eig))
diag(sqrt(eig))
eigvector
deg2rad = function(deg){
rad = deg*pi/180
return(rad)
}
rad2deg = function(rad){
deg = 180/pi*rad
return(deg)
}
cos(deg2rad(60))
rad2deg(acos(30))
rad2deg(acos(deg2rad(30)))
rad2deg(acos(0.2))
n = 72
n - (n/2)
deg2rad = function(deg){
rad = deg*pi/180
return(rad)
}
rad2deg = function(rad){
deg = 180/pi*rad
return(deg)
}
cos(deg2rad(45.2))
cos(deg2rad(55.2))
dat <- rbind(c(32, 64, 65, 67),
c(61, 37, 62, 65),
c(59, 40, 45, 43),
c(36, 62, 34, 35),
c(62, 46, 43, 40))
dat
corr(dat)
cor(dat)
500+400+900+100+1000+500
400+200+600+800+800+400
A=[1 3 5 7;2 4 4 8; 3 1 2 3; 4 3 2 1]
A=[1 3 5 7;2 4 4 8; 3 1 2 3; 4 3 2 1]
A = c(1 3 5 7;2 4 4 8; 3 1 2 3; 4 3 2 1)
A = matrix(c(1, 3, 5, 7,2, 4, 4, 8, 3, 1, 2, 3, 4, 3, 2, 1),4,4)
A
A = matrix(c(1, 3, 5, 7,2, 4, 4, 8, 3, 1, 2, 3, 4, 3, 2, 1),4,4, byrow=T)
A
eig(A)
eigen(A)
m=eigen(A)
m
400+800+1000+600+100+100+400
600+200+1000+1200+100+400
600+200+1000+1200+100+300
500+1000+100+1000+800+200
77(79)
77/79
2.235^5
2.235^4
note = readClipboard()
note
table(note)
400+3*800+100+200+300
install.packages(c("bit", "blob", "broom", "bslib", "cachem", "callr", "car", "cli", "colorspace", "cpp11", "crayon", "crul", "curl", "data.table", "DBI", "dbplyr", "DEoptim", "desc", "deSolve", "digest", "dplyr", "dtplyr", "evaluate", "fansi", "farver", "fastmap", "forcats", "fs", "gamlss.dist", "gargle", "generics", "ggplot2", "googlesheets4", "gplots", "gtable", "gtools", "haven", "highr", "hms", "htmltools", "httr", "isoband", "jsonlite", "knitr", "lifecycle", "lme4", "lubridate", "magrittr", "maptools", "MatrixModels", "minqa", "mnormt", "modelr", "NbClust", "openssl", "osfr", "pbapply", "pbkrtest", "pillar", "pkgload", "plyr", "processx", "ps", "purrr", "qap", "quantreg", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "RColorBrewer", "Rcpp", "RcppEigen", "readr", "readxl", "reprex", "rlang", "rmarkdown", "rstudioapi", "rvest", "sass", "scales", "seriation", "sp", "stringi", "stringr", "sys", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "triebeard", "TSP", "tzdb", "utf8", "uuid", "vctrs", "viridisLite", "vroom", "xfun", "yaml"))
install.packages(c("bit", "blob", "broom", "bslib", "cachem", "callr", "car", "cli", "colorspace", "cpp11", "crayon", "crul", "curl", "data.table", "DBI", "dbplyr", "DEoptim", "desc", "deSolve", "digest", "dplyr", "dtplyr", "evaluate", "fansi", "farver", "fastmap", "forcats", "fs", "gamlss.dist", "gargle", "generics", "ggplot2", "googlesheets4", "gplots", "gtable", "gtools", "haven", "highr", "hms", "htmltools", "httr", "isoband", "jsonlite", "knitr", "lifecycle", "lme4", "lubridate", "magrittr", "maptools", "MatrixModels", "minqa", "mnormt", "modelr", "NbClust", "openssl", "osfr", "pbapply", "pbkrtest", "pillar", "pkgload", "plyr", "processx", "ps", "purrr", "qap", "quantreg", "R.matlab", "R.methodsS3", "R.oo", "R.utils", "RColorBrewer", "Rcpp", "RcppEigen", "readr", "readxl", "reprex", "rlang", "rmarkdown", "rstudioapi", "rvest", "sass", "scales", "seriation", "sp", "stringi", "stringr", "sys", "testthat", "tibble", "tidyr", "tidyselect", "tidyverse", "tinytex", "triebeard", "TSP", "tzdb", "utf8", "uuid", "vctrs", "viridisLite", "vroom", "xfun", "yaml"))
install.packages("fs")
library(quickpsy)
?quickpsy
library(ez)
?ezANOVA
install.packages('ez')
install.packages("ez")
?aov
library(lmer)
library(lme4)
?lmer
(1100 - 200)*0.2
(5500 - 200)*0.2
(550 - 200)*0.2
(550*0.2
)
(1000*0.2)
500+400+200+100+200+300+400+500+600+700
code = 212.50
key = 373.33
4*code + 2*key
212.5/1500
codeprz = 212.5/1500
keyprz = key/1500
rut = 1719.15
rut*keyprz
rut*keyprz + rut*2*codeprz
4*212.50
4*212.50 + 3*373.33
all=4*212.50 + 3*373.33
212.5/all
onecode = 212.5/all
onekey = 373.33/all
1719.15*onecode
1719.15*onecode*2
1719.15*onecode*2 + 1719.15*onekey
1719.15*onecode*2 + 1719.15*onekey*2
0.3635321*1719.15
onecode*2 + onekey
p <- 1 - pf(3.88, 1, 17)
F <- qf(p=.12, df1=1, df2=17, lower.tail=FALSE)
vp         <- c('S01', 'S02', 'S03', 'S04')
contrast   <- seq(0.2, 0.4, by = 0.05)
luminance  <- c(10, 50, 70, 170)
data.frame(vp = rep(vp, each = 20),
contrast = rep(rep(contrast, each = 4), times = 4),
luminance = rep(luminance, times = 20))
setwd('C:\Users\LocalAdmin\Downloads\BCI')
pluseins <- function(x, vec){
x + vec
}
x = c(1,2,3)
vec = seq(1,10,1)
pluseins(x, vec)
lapply(list(x), pluseins(vec)))
lapply(list(x), pluseins(vec))
?Vectorize()
pe <- Vectorize(pluseins, "x")
pe(x, vec)
dd = c(1,2,3)
ee = seq(1,10,1)
pe(dd, ee)
?mapply
mapply(pluseins, x, vec)
mapply(pluseins, x=dd, vec=ee)
mapply(pluseins, x, MoreArgs = list(vec))
pluseins <- function(x, vec){
mapply(pluseins, x, MoreArgs = list(vec))
}
pluseins(3:6, 1:10)
pluseins(3:6, 1:10)
pluseins(3:6, 1:3)
setwd('C:\Users\LocalAdmin\Documents\Git\BCI_neurofeedback\raw')
setwd('C:/Users/LocalAdmin/Documents/Git/BCI_neurofeedback/raw')
library(tidyverse)
library(lubridate) # for time / date data type; package is part of tidyverse
library(R.matlab)  # for reading Matlab's *.mat-files into R; you might need to install that package
# file list with subjects SD1 and JG1 in EEG excluded
fileList <- c("AL1_BCIcar.mat", "AW7_BCIcar.mat", "SD1_BCIcar.mat",
"JG1_BCIcar.mat", "NH1_BCIcar.mat", "SB1_BCIcar.mat",
"AL1_BCIcar_EEG.mat", "AW7_BCIcar_EEG.mat",
"NH1_BCIcar_EEG.mat", "SB1_BCIcar_EEG.mat")
# define function for reading in single subject behavioral data
get_raw <- function(fileName){
# read protocol file and extract information on monitor refresh rate and resolution
tmp                <- readMat(fileName)$BCIcar
yResolution        <- tmp[["resolution", 1, 1]][2]
hz                 <- tmp[["hz", 1, 1]][1]
outmat             <- tmp[["outmat", 1, 1]]
# set monitor dimensions etc. contingent on experimental setup
if(str_detect(fileName, 'car_EEG')){
height_mm       <- 310 # Monitor height in mm, ViewPixx
collisionDist   <- 720 # pixels between obstacle and car at trial start
bugPlus <- 0.45        # increment in pixel speed
r1 <- outmat[, 5]      # correlation between SSVEP and luminance modulation of HF (left) stimulus
r2 <- outmat[, 6]      # correlation between SSVEP and luminance modulation of LF (right) stimulus
} else {
height_mm     <- 165 # Monitor height in mm, Dell Latitude 6320
collisionDist <- 468 # pixels between obstacle and car at trial start
bugPlus <- 1         # increment in pixel speed
r1 <- NA             # SSVEP correlation, NA in behavioral task
r2 <- NA             # SSVEP correlation, NA in behavioral task
}
# correct bug in stimulation routine (outmat entries after failed trails)
bugIndx            <- which(diff(outmat[, 2]) == 0 & diff(outmat[, 4]) == -1) +1
outmat[bugIndx, 2] <- outmat[bugIndx, 2] + bugPlus
# construct tibble, compute time to collide (ttc)
outmat %>%
as_tibble() %>%
mutate(vp = as_factor(tmp[["vp", 1, 1]]),
trial = V1,
speed   = round((V2 * hz) * (height_mm / yResolution)), # mm per second
ttc     = round(collisionDist / (V2 * hz) * 1000), # time to collide, in milliseconds
obstacle = as_factor(V3),
obstacle = fct_recode(obstacle,
left  = "-1",
right = "1"),
outcome = as_factor(V4),
outcome = fct_recode(outcome,
pass  = "1",
fail  = "0"),
experiment = tmp[["experiment", 1, 1]][1],
date    = as_datetime(tmp[["date", 1, 1]][1]),
HFleft      = as.numeric(r1),
LFright     = as.numeric(r2)) %>%
select(vp, trial, speed, ttc, obstacle, outcome, HFleft, LFright, experiment, date)
}
# apply function to each raw data file and concatenate
allVp <- map_df(fileList, get_raw)
# compute cumulative probability for success at increasing levels of ttc
allProb <- allVp %>%
group_by(vp, ttc, experiment) %>%
summarize(n       = n(),
n_pass  = sum(outcome == 'pass')) %>%
group_by(vp, experiment)  %>%
mutate(cumsum_pass  = cumsum(n_pass),
cumprop_pass = cumsum_pass / sum(n)) %>%
ungroup() %>%
select(vp, ttc, n, n_pass, cumprop_pass, experiment)
# aggregate across participants
grandMean = allProb %>%
group_by(ttc, experiment) %>%
summarize(m  = mean(cumprop_pass),
se = sd(cumprop_pass)/sqrt(n())) %>%
ungroup()
grandMean
a = rnorm(500,200, 80)
a
a = rnorm(80,500, 200)
plot(cumsum(a))
a = rnorm(80,500, 200) + rnorm(80,500,50)
plot(cumsum(a))
ecdf(a)
plot(ecdf(a))
a = rnorm(80,500, 200)
plot(ecdf(a))
plot(ecdf(a), type='l')
a1=ecdf(a)
a1
a = rnorm(80,500, 100)
a1=ecdf(a)
plot(a1$x)
str(a1)
a1=quantile(ecdf(a), seq(0,1,0.05))
a1
plot(quantile(ecdf(a), seq(0,1,0.05), seq(0,1,0.05))
)
plot(quantile(ecdf(a), seq(0,1,0.05)), seq(0,1,0.05)
)
plot(quantile(ecdf(a), seq(0,1,0.05)), seq(0,1,0.05), type='l'
)
plot(quantile(ecdf(a), seq(0,1,0.05)), seq(0,1,0.05), type='l', lwd=2)
plot(quantile(ecdf(a), seq(0,1,0.05)), seq(0,1,0.05), type='l', lwd=2, xlim=c(0,2000), xlab='Geschwindigkeit', ylab = 'p (korrekt)')
plot(quantile(ecdf(a), seq(0,1,0.05)), seq(0,1,0.05), type='l', lwd=2, xlim=c(0,1200), xlab='Geschwindigkeit', ylab = 'p (korrekt)')
b = rnorm(80,800, 150)
lines(quantile(ecdf(b), seq(0,0.8,0.05)), seq(0,0.8,0.05), type='l', lwd=2, col='red')
filename <- "NH1_BCIcar_EEG.mat"
tmp                <- readMat(fileName)$BCIcar
fileName <- "NH1_BCIcar_EEG.mat"
tmp                <- readMat(fileName)$BCIcar
tmp
tmp[["resolution,1,1"]]
tmp[["resolution",1,1]]
simplify(tmp)
drop(tmp)
s=drop(tmp)
s
s$vp
s$date
s$experiment
